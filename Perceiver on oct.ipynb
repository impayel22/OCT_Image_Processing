{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5Mu4UvrdIAR","executionInfo":{"status":"ok","timestamp":1662869254171,"user_tz":-360,"elapsed":730,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"64bd7ab4-4df8-41ba-eda8-db7c489e5e51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 11 04:07:34 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"metadata":{"id":"pDqmpDZPdTNz","executionInfo":{"status":"ok","timestamp":1662869254837,"user_tz":-360,"elapsed":3,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#!unzip -u \"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/Image Processing/Alpha Beta on Median Erosion/NORMALA.zip\" -d \"/content/OCT_Dataset\"\n","\n","#print('\\n\\ndone!')"],"metadata":{"id":"1XcejbJgdVnH","executionInfo":{"status":"ok","timestamp":1662869254838,"user_tz":-360,"elapsed":4,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","import tensorflow as tf\n","\n","import cv2\n","import os\n","\n","import numpy as np"],"metadata":{"id":"HSdk9-lCdYum","executionInfo":{"status":"ok","timestamp":1662869260422,"user_tz":-360,"elapsed":5587,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["labels = [\"CNVA\", \"DMEA\",\"DRUSENA\", \"NORMALA\"]\n","img_size = 32\n","def get_data(data_dir):\n","    data = [] \n","    for label in labels: \n","        path = os.path.join(data_dir, label)\n","        class_num = labels.index(label)\n","        for img in os.listdir(path):\n","            try:\n","                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n","                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n","                data.append([resized_arr, class_num])\n","            except Exception as e:\n","                print(e)\n","    return np.array(data)"],"metadata":{"id":"II6hA280dc9S","executionInfo":{"status":"ok","timestamp":1662869260423,"user_tz":-360,"elapsed":13,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train = get_data('/content/OCT_Dataset')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8jHTHS8dfuE","executionInfo":{"status":"ok","timestamp":1662869455662,"user_tz":-360,"elapsed":195251,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"4992b36a-8b61-4f5f-e872-c20460638ba9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  from ipykernel import kernelapp as app\n"]}]},{"cell_type":"code","source":["l = []\n","for i in train:\n","    if(i[1] == 0):\n","        l.append(\"CNVA\")\n","    elif(i[1] == 1):\n","          l.append(\"DMEA\")\n","    elif(i[1] == 2):\n","          l.append(\"DRUSENA\")\n","    elif(i[1] == 3):\n","          l.append(\"NORMALA\")\n","       \n","sns.set_style('darkgrid')\n","sns.countplot(l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"le5rgES4djEj","executionInfo":{"status":"ok","timestamp":1662869455663,"user_tz":-360,"elapsed":25,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"a91384d2-7dfd-4008-bb5f-0f9e337cb868"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fcad7ddbfd0>"]},"metadata":{},"execution_count":7},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["plt.figure(figsize = (5,5))\n","plt.imshow(train[1][0])\n","plt.title(labels[train[0][1]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"TaMFjQLddjyV","executionInfo":{"status":"ok","timestamp":1662869456444,"user_tz":-360,"elapsed":792,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"affdff9a-bdc3-4555-e141-7adcccc44d3c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'CNVA')"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"text/plain":["<Figure size 360x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["x_train = []\n","y_train = []\n","\n","\n","for feature, label in train:\n","  x_train.append(feature)\n","  y_train.append(label)\n","x_train = np.array(x_train) / 255\n","x_train.reshape(-1, img_size, img_size, 1)\n","y_train = np.array(y_train)"],"metadata":{"id":"8qEgmCw-dpT8","executionInfo":{"status":"ok","timestamp":1662869457123,"user_tz":-360,"elapsed":682,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# split with a stratified sampling\n","from sklearn.model_selection import train_test_split\n","(x_train, x_test, y_train, y_test) = train_test_split(x_train, y_train,\n","    test_size=0.15, stratify=y_train, random_state=42)"],"metadata":{"id":"HHF4Cl6cdsHW","executionInfo":{"status":"ok","timestamp":1662869459341,"user_tz":-360,"elapsed":2219,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!pip install -U -q tensorflow-addons"],"metadata":{"id":"ylcPtghQdsz8","executionInfo":{"status":"ok","timestamp":1662869462781,"user_tz":-360,"elapsed":3443,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","import numpy as np"],"metadata":{"id":"h5dPXnlldyR0","executionInfo":{"status":"ok","timestamp":1662869462782,"user_tz":-360,"elapsed":13,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["y_train = keras.utils.to_categorical(\n","    y_train, num_classes=4, dtype='float32'\n",")\n","y_test = keras.utils.to_categorical(\n","    y_test, num_classes=4, dtype='float32'\n",")\n"],"metadata":{"id":"K49szk-ld14w","executionInfo":{"status":"ok","timestamp":1662869462782,"user_tz":-360,"elapsed":12,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["num_classes = 4\n","input_shape = (32, 32, 3)\n","class_mode=\"softmax\""],"metadata":{"id":"p1Y0iFdzamnR","executionInfo":{"status":"ok","timestamp":1662869462782,"user_tz":-360,"elapsed":11,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-5OW7M3eCDm","executionInfo":{"status":"ok","timestamp":1662869462783,"user_tz":-360,"elapsed":11,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"ef59ce20-6727-407a-ed16-baa2d7228bc7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (111475, 32, 32, 3) - y_train shape: (111475, 4)\n","x_test shape: (19673, 32, 32, 3) - y_test shape: (19673, 4)\n"]}]},{"cell_type":"code","source":["learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 128\n","num_epochs = 100\n","dropout_rate = 0.2\n","image_size = 32  # We'll resize input images to this size.\n","patch_size = 2  # Size of the patches to be extract from the input images.\n","num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n","latent_dim = 64  # Size of the latent array.\n","projection_dim = 64  # Embedding size of each element in the data and latent arrays.\n","num_heads = 4  # Number of Transformer heads.\n","ffn_units = [\n","    projection_dim,\n","    projection_dim,\n","]  # Size of the Transformer Feedforward network.\n","num_transformer_blocks = 4\n","num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n","classifier_units = [\n","    projection_dim,\n","    num_classes,\n","]  # Size of the Feedforward network of the final classifier.\n","\n","print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n","print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n","print(f\"Patches per image: {num_patches}\")\n","print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n","print(f\"Latent array shape: {latent_dim} X {projection_dim}\")\n","print(f\"Data array shape: {num_patches} X {projection_dim}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-r2eKY-BasT5","executionInfo":{"status":"ok","timestamp":1662870013327,"user_tz":-360,"elapsed":473,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"18a4bea9-4633-472d-9ed2-7026bd390661"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Image size: 32 X 32 = 1024\n","Patch size: 2 X 2 = 4 \n","Patches per image: 256\n","Elements per patch (3 channels): 12\n","Latent array shape: 64 X 64\n","Data array shape: 256 X 64\n"]}]},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(image_size, image_size),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","# Compute the mean and the variance of the training data for normalization.\n","data_augmentation.layers[0].adapt(x_train)"],"metadata":{"id":"a3dXGUkXasWk","executionInfo":{"status":"ok","timestamp":1662870024645,"user_tz":-360,"elapsed":6513,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def create_ffn(hidden_units, dropout_rate):\n","    ffn_layers = []\n","    for units in hidden_units[:-1]:\n","        ffn_layers.append(layers.Dense(units, activation=tf.nn.elu))\n","\n","    ffn_layers.append(layers.Dense(units=hidden_units[-1]))\n","    ffn_layers.append(layers.Dropout(dropout_rate))\n","\n","    ffn = keras.Sequential(ffn_layers)\n","    return ffn"],"metadata":{"id":"OP1llM7FasZO","executionInfo":{"status":"ok","timestamp":1662870028712,"user_tz":-360,"elapsed":5,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"],"metadata":{"id":"5p0FF8ptasbt","executionInfo":{"status":"ok","timestamp":1662870030588,"user_tz":-360,"elapsed":1,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patches):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patches) + self.position_embedding(positions)\n","        return encoded"],"metadata":{"id":"xbO_vgqNaseg","executionInfo":{"status":"ok","timestamp":1662870032186,"user_tz":-360,"elapsed":4,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def create_cross_attention_module(\n","    latent_dim, data_dim, projection_dim, ffn_units, dropout_rate\n","):\n","\n","    inputs = {\n","        # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n","        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n","        # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n","        \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n","    }\n","\n","    # Apply layer norm to the inputs\n","    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n","    data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n","\n","    # Create query tensor: [1, latent_dim, projection_dim].\n","    query = layers.Dense(units=projection_dim)(latent_array)\n","    # Create key tensor: [batch_size, data_dim, projection_dim].\n","    key = layers.Dense(units=projection_dim)(data_array)\n","    # Create value tensor: [batch_size, data_dim, projection_dim].\n","    value = layers.Dense(units=projection_dim)(data_array)\n","\n","    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n","    attention_output = layers.Attention(use_scale=True, dropout=0.1)(\n","        [query, key, value], return_attention_scores=False\n","    )\n","    # Skip connection 1.\n","    attention_output = layers.Add()([attention_output, latent_array])\n","\n","    # Apply layer norm.\n","    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n","    # Apply Feedforward network.\n","    ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n","    outputs = ffn(attention_output)\n","    # Skip connection 2.\n","    outputs = layers.Add()([outputs, attention_output])\n","\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model"],"metadata":{"id":"PpeCsI8yashG","executionInfo":{"status":"ok","timestamp":1662870032187,"user_tz":-360,"elapsed":4,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def create_transformer_module(\n","    latent_dim,\n","    projection_dim,\n","    num_heads,\n","    num_transformer_blocks,\n","    ffn_units,\n","    dropout_rate,\n","):\n","\n","    # input_shape: [1, latent_dim, projection_dim]\n","    inputs = layers.Input(shape=(latent_dim, projection_dim))\n","\n","    x0 = inputs\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(num_transformer_blocks):\n","        # Apply layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(x0)\n","        # Create a multi-head self-attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, x0])\n","        # Apply layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # Apply Feedforward network.\n","        ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n","        x3 = ffn(x3)\n","        # Skip connection 2.\n","        x0 = layers.Add()([x3, x2])\n","\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=x0)\n","    return model"],"metadata":{"id":"lWkeNIWOasjj","executionInfo":{"status":"ok","timestamp":1662870034384,"user_tz":-360,"elapsed":2,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class Perceiver(keras.Model):\n","    def __init__(\n","        self,\n","        patch_size,\n","        data_dim,\n","        latent_dim,\n","        projection_dim,\n","        num_heads,\n","        num_transformer_blocks,\n","        ffn_units,\n","        dropout_rate,\n","        num_iterations,\n","        classifier_units,\n","    ):\n","        super(Perceiver, self).__init__()\n","\n","        self.latent_dim = latent_dim\n","        self.data_dim = data_dim\n","        self.patch_size = patch_size\n","        self.projection_dim = projection_dim\n","        self.num_heads = num_heads\n","        self.num_transformer_blocks = num_transformer_blocks\n","        self.ffn_units = ffn_units\n","        self.dropout_rate = dropout_rate\n","        self.num_iterations = num_iterations\n","        self.classifier_units = classifier_units\n","\n","    def build(self, input_shape):\n","        # Create latent array.\n","        self.latent_array = self.add_weight(\n","            shape=(self.latent_dim, self.projection_dim),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","\n","        # Create patching module.\n","        self.patcher = Patches(self.patch_size)\n","\n","        # Create patch encoder.\n","        self.patch_encoder = PatchEncoder(self.data_dim, self.projection_dim)\n","\n","        # Create cross-attenion module.\n","        self.cross_attention = create_cross_attention_module(\n","            self.latent_dim,\n","            self.data_dim,\n","            self.projection_dim,\n","            self.ffn_units,\n","            self.dropout_rate,\n","        )\n","\n","        # Create Transformer module.\n","        self.transformer = create_transformer_module(\n","            self.latent_dim,\n","            self.projection_dim,\n","            self.num_heads,\n","            self.num_transformer_blocks,\n","            self.ffn_units,\n","            self.dropout_rate,\n","        )\n","\n","        # Create global average pooling layer.\n","        self.global_average_pooling = layers.GlobalMaxPooling1D()\n","\n","        # Create a classification head.\n","        self.classification_head = create_ffn(\n","            hidden_units=self.classifier_units, dropout_rate=self.dropout_rate\n","        )\n","\n","        super(Perceiver, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        # Augment data.\n","        augmented = data_augmentation(inputs)\n","        # Create patches.\n","        patches = self.patcher(augmented)\n","        # Encode patches.\n","        encoded_patches = self.patch_encoder(patches)\n","        # Prepare cross-attention inputs.\n","        cross_attention_inputs = {\n","            \"latent_array\": tf.expand_dims(self.latent_array, 0),\n","            \"data_array\": encoded_patches,\n","        }\n","        # Apply the cross-attention and the Transformer modules iteratively.\n","        for _ in range(self.num_iterations):\n","            # Apply cross-attention from the latent array to the data array.\n","            latent_array = self.cross_attention(cross_attention_inputs)\n","            # Apply self-attention Transformer to the latent array.\n","            latent_array = self.transformer(latent_array)\n","            # Set the latent array of the next iteration.\n","            cross_attention_inputs[\"latent_array\"] = latent_array\n","\n","        # Apply global average pooling to generate a [batch_size, projection_dim] repesentation tensor.\n","        representation = self.global_average_pooling(latent_array)\n","        # Generate logits.\n","        logits = self.classification_head(representation)\n","        return logits"],"metadata":{"id":"8FfH_O1pasm9","executionInfo":{"status":"ok","timestamp":1662870037262,"user_tz":-360,"elapsed":11,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"1dCnGz_Zqjw7","executionInfo":{"status":"ok","timestamp":1662869478465,"user_tz":-360,"elapsed":14,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def run_experiment(model):\n","\n","    # Create LAMB optimizer with weight decay.\n","    optimizer = tfa.optimizers.LAMB(\n","        learning_rate=learning_rate, weight_decay_rate=weight_decay,\n","    )\n","\n","    # Compile the model.\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n","            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n","        ],\n","    )\n","\n","    # Create a learning rate scheduler callback.\n","    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n","        monitor=\"val_loss\", factor=0.2, patience=3\n","    )\n","\n","    # Create an early stopping callback.\n","    early_stopping = tf.keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\", patience=15, restore_best_weights=True\n","    )\n","\n","    # Fit the model.\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=num_epochs,\n","        validation_split=0.1,\n","        callbacks=[early_stopping, reduce_lr],\n","    )\n","\n","    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    # Return history to plot learning curves.\n","    return history"],"metadata":{"id":"TcjW1-Csaspo","executionInfo":{"status":"ok","timestamp":1662870053031,"user_tz":-360,"elapsed":3655,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["perceiver_classifier = Perceiver(\n","    patch_size,\n","    num_patches,\n","    latent_dim,\n","    projection_dim,\n","    num_heads,\n","    num_transformer_blocks,\n","    ffn_units,\n","    dropout_rate,\n","    num_iterations,\n","    classifier_units,\n",")\n","\n","\n","history = run_experiment(perceiver_classifier)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":779},"id":"hVmAGPKbasve","executionInfo":{"status":"error","timestamp":1662870065869,"user_tz":-360,"elapsed":11107,"user":{"displayName":"Sadia Image","userId":"03169694580906039628"}},"outputId":"8f1631b0-3b15-4811-ff29-ad03c7d45514"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-6127dad97188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceiver_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-35-26fb2031b275>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 729, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 4078, in sparse_categorical_accuracy\n        y_true = tf.squeeze(y_true, [-1])\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 4 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](IteratorGetNext:1)' with input shapes: [?,4].\n"]}]}]}