{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4936,"status":"ok","timestamp":1662552571092,"user":{"displayName":"SADIA SULTANA CHOWA 201-15-3052","userId":"15830984332084645242"},"user_tz":-360},"id":"1FFv5Qhjh-Gx","outputId":"bce45b3e-8fad-4e85-88b2-855a2fdc7721"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 10.1 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard\u003e=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.17.1\n"]}],"source":["pip install -U tensorflow-addons"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1209,"status":"ok","timestamp":1662552572287,"user":{"displayName":"SADIA SULTANA CHOWA 201-15-3052","userId":"15830984332084645242"},"user_tz":-360},"id":"XE1T-UtskFVW","outputId":"b0a835bc-89f9-449e-d9c7-0d85d38b731a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Sep  7 12:09:30 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kVZiLaSKlW7G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWN9xjFGlVCF"},"outputs":[],"source":["!unzip -u \"/content/drive/MyDrive/OCT Project/OCT Code \u0026 Dataset/OCT Gamma.zip\" -d \"/content/OCT_Dataset\"\n","\n","print('\\n\\ndone!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGBSGG1JkLNi"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","import tensorflow as tf\n","\n","import cv2\n","import os\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-U6H-jcvKld"},"outputs":[],"source":["labels = [\"COVID\", \"Lung_Opacity\",\"Normal\", \"Viral Pneumonia\"]\n","img_size = 32\n","def get_data(data_dir):\n","    data = [] \n","    for label in labels: \n","        path = os.path.join(data_dir, label)\n","        class_num = labels.index(label)\n","        for img in os.listdir(path):\n","            try:\n","                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n","                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n","                data.append([resized_arr, class_num])\n","            except Exception as e:\n","                print(e)\n","    return np.array(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYvlenRgvKoE"},"outputs":[],"source":["train = get_data('/content/Balenced dataset 50000')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgutstXBvKq2"},"outputs":[],"source":["l = []\n","for i in train:\n","    if(i[1] == 0):\n","        l.append(\"COVID\")\n","    elif(i[1] == 1):\n","          l.append(\"Lung_Opacity\")\n","    elif(i[1] == 2):\n","          l.append(\"Normal\")\n","    elif(i[1] == 3):\n","          l.append(\"Viral Pneumonia\")\n","       \n","sns.set_style('darkgrid')\n","sns.countplot(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIXQokeAvKt0"},"outputs":[],"source":["plt.figure(figsize = (5,5))\n","plt.imshow(train[1][0])\n","plt.title(labels[train[0][1]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urQWlzqVvKwo"},"outputs":[],"source":["x_train = []\n","y_train = []\n","\n","\n","for feature, label in train:\n","  x_train.append(feature)\n","  y_train.append(label)\n","x_train = np.array(x_train) / 255\n","x_train.reshape(-1, img_size, img_size, 1)\n","y_train = np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgxvNeqXvKza"},"outputs":[],"source":["# split with a stratified sampling\n","from sklearn.model_selection import train_test_split\n","(x_train, x_test, y_train, y_test) = train_test_split(x_train, y_train,\n","    test_size=0.15, stratify=y_train, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5-AhznRvK2N"},"outputs":[],"source":["!pip install -U -q tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qS0xOdTvK46"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOcVgAvlvK8J"},"outputs":[],"source":["y_train = keras.utils.to_categorical(\n","    y_train, num_classes=4, dtype='float32'\n",")\n","y_test = keras.utils.to_categorical(\n","    y_test, num_classes=4, dtype='float32'\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1ZNX9G4vK_m"},"outputs":[],"source":["num_classes = 4\n","input_shape = (32, 32, 3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujNZdXr-Z3Jh"},"outputs":[],"source":["weight_decay = 0.0001\n","learning_rate = 0.001\n","label_smoothing = 0.1\n","validation_split = 0.2\n","batch_size = 128\n","num_epochs = 2\n","patch_size = 2  # Size of the patches to be extracted from the input images.\n","num_patches = (input_shape[0] // patch_size) ** 2  # Number of patch\n","embedding_dim = 64  # Number of hidden units.\n","mlp_dim = 64\n","dim_coefficient = 4\n","num_heads = 4\n","attention_dropout = 0.2\n","projection_dropout = 0.2\n","num_transformer_blocks = 8  # Number of repetitions of the transformer layer\n","\n","print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n","print(f\"Patches per image: {num_patches}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOXCCXgfZ3MV"},"outputs":[],"source":["print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6EqM4OUZ3PY"},"outputs":[],"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.1),\n","        layers.RandomContrast(factor=0.1),\n","        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","# Compute the mean and the variance of the training data for normalization.\n","data_augmentation.layers[0].adapt(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VU6o8Z11Z3SC"},"outputs":[],"source":["class PatchExtract(layers.Layer):\n","    def __init__(self, patch_size, **kwargs):\n","        super(PatchExtract, self).__init__(**kwargs)\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=(1, self.patch_size, self.patch_size, 1),\n","            strides=(1, self.patch_size, self.patch_size, 1),\n","            rates=(1, 1, 1, 1),\n","            padding=\"VALID\",\n","        )\n","        patch_dim = patches.shape[-1]\n","        patch_num = patches.shape[1]\n","        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n","\n","\n","class PatchEmbedding(layers.Layer):\n","    def __init__(self, num_patch, embed_dim, **kwargs):\n","        super(PatchEmbedding, self).__init__(**kwargs)\n","        self.num_patch = num_patch\n","        self.proj = layers.Dense(embed_dim)\n","        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n","\n","    def call(self, patch):\n","        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n","        return self.proj(patch) + self.pos_embed(pos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KqIGnvV8Z3U3"},"outputs":[],"source":["def external_attention(\n","    x, dim, num_heads, dim_coefficient=4, attention_dropout=0, projection_dropout=0\n","):\n","    _, num_patch, channel = x.shape\n","    assert dim % num_heads == 0\n","    num_heads = num_heads * dim_coefficient\n","\n","    x = layers.Dense(dim * dim_coefficient)(x)\n","    # create tensor [batch_size, num_patches, num_heads, dim*dim_coefficient//num_heads]\n","    x = tf.reshape(\n","        x, shape=(-1, num_patch, num_heads, dim * dim_coefficient // num_heads)\n","    )\n","    x = tf.transpose(x, perm=[0, 2, 1, 3])\n","    # a linear layer M_k\n","    attn = layers.Dense(dim // dim_coefficient)(x)\n","    # normalize attention map\n","    attn = layers.Softmax(axis=2)(attn)\n","    # dobule-normalization\n","    attn = attn / (1e-9 + tf.reduce_sum(attn, axis=-1, keepdims=True))\n","    attn = layers.Dropout(attention_dropout)(attn)\n","    # a linear layer M_v\n","    x = layers.Dense(dim * dim_coefficient // num_heads)(attn)\n","    x = tf.transpose(x, perm=[0, 2, 1, 3])\n","    x = tf.reshape(x, [-1, num_patch, dim * dim_coefficient])\n","    # a linear layer to project original dim\n","    x = layers.Dense(dim)(x)\n","    x = layers.Dropout(projection_dropout)(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eo8iBMX3Z3XG"},"outputs":[],"source":["def mlp(x, embedding_dim, mlp_dim, drop_rate=0.2):\n","    x = layers.Dense(mlp_dim, activation=tf.nn.gelu)(x)\n","    x = layers.Dropout(drop_rate)(x)\n","    x = layers.Dense(embedding_dim)(x)\n","    x = layers.Dropout(drop_rate)(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"in3jVlgaZ3Zm"},"outputs":[],"source":["def transformer_encoder(\n","    x,\n","    embedding_dim,\n","    mlp_dim,\n","    num_heads,\n","    dim_coefficient,\n","    attention_dropout,\n","    projection_dropout,\n","    attention_type=\"external_attention\",\n","):\n","    residual_1 = x\n","    x = layers.LayerNormalization(epsilon=1e-5)(x)\n","    if attention_type == \"external_attention\":\n","        x = external_attention(\n","            x,\n","            embedding_dim,\n","            num_heads,\n","            dim_coefficient,\n","            attention_dropout,\n","            projection_dropout,\n","        )\n","    elif attention_type == \"self_attention\":\n","        x = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embedding_dim, dropout=attention_dropout\n","        )(x, x)\n","    x = layers.add([x, residual_1])\n","    residual_2 = x\n","    x = layers.LayerNormalization(epsilon=1e-5)(x)\n","    x = mlp(x, embedding_dim, mlp_dim)\n","    x = layers.add([x, residual_2])\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4fO60JMZ3cY"},"outputs":[],"source":["def get_model(attention_type=\"external_attention\"):\n","    inputs = layers.Input(shape=input_shape)\n","    # Image augment\n","    x = data_augmentation(inputs)\n","    # Extract patches.\n","    x = PatchExtract(patch_size)(x)\n","    # Create patch embedding.\n","    x = PatchEmbedding(num_patches, embedding_dim)(x)\n","    # Create Transformer block.\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(\n","            x,\n","            embedding_dim,\n","            mlp_dim,\n","            num_heads,\n","            dim_coefficient,\n","            attention_dropout,\n","            projection_dropout,\n","            attention_type,\n","        )\n","\n","    x = layers.GlobalAvgPool1D()(x)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9YSAKZ5Z3fa"},"outputs":[],"source":["model = get_model(attention_type=\"external_attention\")\n","\n","model.compile(\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n","    optimizer=tf.keras.optimizers.Adam(\n","    learning_rate=0.001,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=1e-07,\n","    amsgrad=False,\n","    name=\"Adam\"\n","),\n","    metrics=[\n","        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n","        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","    ],\n",")\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    batch_size=batch_size,\n","    epochs=num_epochs,\n","    validation_split=validation_split,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_bg0DwJZ3iQ"},"outputs":[],"source":["plt.plot(history.history[\"loss\"], label=\"train_loss\")\n","plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n","plt.legend()\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJ8SMaa9Z3lK"},"outputs":[],"source":["plt.plot(history.history[\"loss\"], label=\"train_loss\")\n","plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n","plt.legend()\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQfXSUUmosur"},"outputs":[],"source":["loss, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n","print(f\"Test loss: {round(loss, 2)}\")\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","\n","\n","# as I've trained my model on MNIST as odd or even (binary classes)\n","target_names = [\"COVID\", \"Lung_Opacity\", \"Normal\",\"Viral Pneumonia\"]\n","\n","\n","# get predict prob and label \n","ypred = model.predict(x_test, verbose=1)\n","ypred = np.argmax(ypred, axis=1)\n","print(classification_report(np.argmax(y_test, axis=1), ypred, target_names=target_names))\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd \n","\n","cm = confusion_matrix(np.argmax(y_test, axis=1), ypred)\n","cm = pd.DataFrame(cm, range(4),range(4))\n","plt.figure(figsize = (10,10))\n","\n","sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwR4AvYHosx3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNyvowAKos0w"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}