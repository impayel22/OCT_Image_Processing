{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OCT_drusen4_GAN1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bH7TfMem9Nko","executionInfo":{"status":"ok","timestamp":1661515048485,"user_tz":-360,"elapsed":410,"user":{"displayName":"Sadia Sultana Chowa","userId":"01731410911290069381"}},"outputId":"d1bfdaf6-ef7d-425d-d91e-5170387dc2e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Aug 26 11:57:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P0    26W /  70W |    506MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","source":["! pip uninstall tensorflow \n","! pip install tensorflow==2.3.0"],"metadata":{"id":"aW8KrgtqMBPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"OT4bbXie3j7k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661515052674,"user_tz":-360,"elapsed":3527,"user":{"displayName":"Sadia Sultana Chowa","userId":"01731410911290069381"}},"outputId":"839d9740-0ee7-4c9e-da7e-7d5cf2dfa8dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!unzip -u \"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/drusen_4.zip\" -d \"/content\"\n","\n","print('\\n\\ndone!')"],"metadata":{"id":"KLs6NSUS9-uS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import glob\n","import os\n","#-------------------------------------------------gray--------------------------------------------------\n","input = \"/content/drusen_3\"\n","i = 0\n","\n","for im in os.listdir(input):  \n","    path = os.path.join(input,im)\n","    img = cv2.imread(path) \n","    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    cv2.imwrite(os.path.join(\"/content/Drusen_3_grey\",\"drusen_3\" +str(i)+'.jpeg'),img)\n","    i += 1"],"metadata":{"id":"m74w6Gz9QWZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","from glob import glob\n","from matplotlib import pyplot\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"FzeiNamFMGul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_H = 224\n","IMG_W = 224\n","IMG_C = 1  ## Change this to 1 for grayscale.\n","w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"],"metadata":{"id":"yKlHpLUkMLNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.io.decode_jpeg(img)\n","    img = tf.image.resize_with_crop_or_pad(img, IMG_H, IMG_W)\n","    img = tf.cast(img, tf.float32)\n","    img = (img - 127.5) / 127.5\n","    return img"],"metadata":{"id":"UT1MQr6gMPG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_dataset(images_path, batch_size):\n","    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n","    dataset = dataset.shuffle(buffer_size=10240)\n","    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"EWmr4lLiMSn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n","    x = Conv2DTranspose(\n","        filters=num_filters,\n","        kernel_size=kernel_size,\n","        kernel_initializer=w_init,\n","        padding=\"same\",\n","        strides=strides,\n","        use_bias=False\n","        )(inputs)\n","\n","    if bn:\n","        x = BatchNormalization()(x)\n","        x = LeakyReLU(alpha=0.2)(x)\n","    return x"],"metadata":{"id":"csaAakZaMVOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation=True):\n","    x = Conv2D(\n","        filters=num_filters,\n","        kernel_size=kernel_size,\n","        kernel_initializer=w_init,\n","        padding=padding,\n","        strides=strides,\n","    )(inputs)\n","\n","    if activation:\n","        x = LeakyReLU(alpha=0.2)(x)\n","        x = Dropout(0.3)(x)\n","    return x"],"metadata":{"id":"QwcrD0n8MaDZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_generator(latent_dim):\n","    f = [2**i for i in range(5)][::-1]\n","    filters = 32\n","    output_strides = 16\n","    h_output = IMG_H // output_strides\n","    w_output = IMG_W // output_strides\n","\n","    noise = Input(shape=(latent_dim,), name=\"generator_noise_input\")\n","\n","    x = Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Reshape((h_output, w_output, 16 * filters))(x)\n","\n","    for i in range(1, 5):\n","        x = deconv_block(x,\n","            num_filters=f[i] * filters,\n","            kernel_size=5,\n","            strides=2,\n","            bn=True\n","        )\n","\n","    x = conv_block(x,\n","        num_filters=1,  ## Change this to 1 for grayscale.\n","        kernel_size=5,\n","        strides=1,\n","        activation=False\n","    )\n","    fake_output = Activation(\"tanh\")(x)\n","\n","    return Model(noise, fake_output, name=\"generator\")\n"],"metadata":{"id":"p3wBOUtWMhMc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Kc02qvA8H7GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_discriminator():\n","    f = [2**i for i in range(4)]\n","    image_input = Input(shape=(IMG_H, IMG_W, IMG_C))\n","    x = image_input\n","    filters = 64\n","    output_strides = 16\n","    h_output = IMG_H // output_strides\n","    w_output = IMG_W // output_strides\n","\n","    for i in range(0, 4):\n","        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)\n","\n","    x = Flatten()(x)\n","    x = Dense(1)(x)\n","\n","    return Model(image_input, x, name=\"discriminator\")\n","\n","class GAN(Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, real_images):\n","        batch_size = tf.shape(real_images)[0]\n","\n","        for _ in range(2):\n","            ## Train the discriminator\n","            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","            generated_images = self.generator(random_latent_vectors)\n","            generated_labels = tf.zeros((batch_size, 1))\n","\n","            with tf.GradientTape() as ftape:\n","                predictions = self.discriminator(generated_images)\n","                d1_loss = self.loss_fn(generated_labels, predictions)\n","            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n","            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","\n","            ## Train the discriminator\n","            labels = tf.ones((batch_size, 1))\n","\n","            with tf.GradientTape() as rtape:\n","                predictions = self.discriminator(real_images)\n","                d2_loss = self.loss_fn(labels, predictions)\n","            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n","            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","\n","        ## Train the generator\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        misleading_labels = tf.ones((batch_size, 1))\n","\n","        with tf.GradientTape() as gtape:\n","            predictions = self.discriminator(self.generator(random_latent_vectors))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss}\n","\n","def save_plot(examples, epoch, n):\n","    examples = (examples + 1) / 2.0\n","    for i in range(n * n):\n","        pyplot.subplot(n, n, i+1)\n","        pyplot.axis(\"off\")\n","        pyplot.imshow(examples[i, :,:,0], cmap='gray')  \n","        #pyplot.imshow(np.squeeze(examples[i], axis=-1))\n","    filename = f\"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/OCT Gan/gan_drusen_3/Output-{epoch+1}.png\"\n","    pyplot.savefig(filename,bbox_inches='tight', pad_inches = 0)\n","    pyplot.close()\n"],"metadata":{"id":"N_jkEwrUMmK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LN3TCorK-2CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    ## Hyperparameters\n","    batch_size = 128\n","    latent_dim = 128\n","    num_epochs = 2000\n","    images_path = glob(\"/content/Drusen_3_grey/*\")\n","\n","    d_model = build_discriminator()\n","    g_model = build_generator(latent_dim)\n","\n","     #d_model.load_weights(\"/content/drive/MyDrive/Dataset orginial/output/output/d_model.h5\")\n","     #g_model.load_weights(\"/content/drive/MyDrive/Dataset orginial/output/output/g_model.h5\")\n","\n","    d_model.summary()\n","    g_model.summary()\n","\n","    gan = GAN(d_model, g_model, latent_dim)\n","\n","    bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n","    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n","    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n","    gan.compile(d_optimizer, g_optimizer, bce_loss_fn)\n","\n","    images_dataset = tf_dataset(images_path, batch_size)\n","\n","    for epoch in range(num_epochs):\n","        gan.fit(images_dataset, epochs=1)\n","        g_model.save(\"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/OCT Gan/gan_drusen_3/Output/g_model.h5\")\n","        d_model.save(\"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/OCT Gan/gan_drusen_3/Output/d_model.h5\")\n","\n","        n_samples = 1\n","        noise = np.random.normal(size=(n_samples, latent_dim))\n","        examples = g_model.predict(noise)\n","        save_plot(examples, epoch, int(np.sqrt(n_samples)))\n"],"metadata":{"id":"1Bb9FzdxMsSD","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e692ca37-0776-4f55-8ceb-5a7b40ede6d4","executionInfo":{"status":"error","timestamp":1661518392796,"user_tz":-360,"elapsed":404792,"user":{"displayName":"Sadia Sultana Chowa","userId":"01731410911290069381"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 112, 112, 64)      1664      \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 56, 56, 128)       204928    \n","_________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 28, 28, 256)       819456    \n","_________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 14, 14, 512)       3277312   \n","_________________________________________________________________\n","leaky_re_lu_12 (LeakyReLU)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 100352)            0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 100353    \n","=================================================================\n","Total params: 4,403,713\n","Trainable params: 4,403,713\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","generator_noise_input (Input [(None, 128)]             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100352)            12845056  \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 100352)            401408    \n","_________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)   (None, 100352)            0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv2d_transpose_4 (Conv2DTr (None, 28, 28, 256)       3276800   \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv2d_transpose_5 (Conv2DTr (None, 56, 56, 128)       819200    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_6 (Conv2DTr (None, 112, 112, 64)      204800    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 112, 112, 64)      256       \n","_________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv2d_transpose_7 (Conv2DTr (None, 224, 224, 32)      51200     \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 224, 224, 32)      128       \n","_________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)   (None, 224, 224, 32)      0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 224, 224, 1)       801       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 224, 224, 1)       0         \n","=================================================================\n","Total params: 17,601,185\n","Trainable params: 17,399,521\n","Non-trainable params: 201,664\n","_________________________________________________________________\n","18/18 [==============================] - 63s 3s/step - d1_loss: 0.4711 - d2_loss: 0.2748 - g_loss: 1.5904\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.3938 - d2_loss: 0.3365 - g_loss: 2.1683\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2187 - d2_loss: 0.2956 - g_loss: 2.2984\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2465 - d2_loss: 0.3465 - g_loss: 2.2370\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2510 - d2_loss: 0.2597 - g_loss: 2.6624\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2148 - d2_loss: 0.2476 - g_loss: 2.5789\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2086 - d2_loss: 0.2519 - g_loss: 2.6159\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2299 - d2_loss: 0.2403 - g_loss: 2.6264\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.6444 - d2_loss: 0.5664 - g_loss: 2.0680\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2108 - d2_loss: 0.2427 - g_loss: 2.7702\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2496 - d2_loss: 0.2798 - g_loss: 2.8187\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2077 - d2_loss: 0.2441 - g_loss: 2.5848\n","18/18 [==============================] - 64s 4s/step - d1_loss: 2.1492 - d2_loss: 0.5756 - g_loss: 3.1448\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2966 - d2_loss: 0.3665 - g_loss: 1.8242\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2392 - d2_loss: 0.3417 - g_loss: 2.2004\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2494 - d2_loss: 0.3066 - g_loss: 2.1819\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2660 - d2_loss: 0.3103 - g_loss: 2.3459\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.3239 - d2_loss: 0.3398 - g_loss: 2.3259\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2560 - d2_loss: 0.3470 - g_loss: 2.0615\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2358 - d2_loss: 0.2790 - g_loss: 2.2255\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2353 - d2_loss: 0.2870 - g_loss: 2.5184\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2376 - d2_loss: 0.2827 - g_loss: 2.6082\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2154 - d2_loss: 0.2549 - g_loss: 2.5165\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2181 - d2_loss: 0.2678 - g_loss: 2.4527\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2199 - d2_loss: 0.2753 - g_loss: 2.6144\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2179 - d2_loss: 0.2579 - g_loss: 2.6461\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.5403 - d2_loss: 1.2672 - g_loss: 2.8829\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.3082 - d2_loss: 0.4373 - g_loss: 1.7259\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2999 - d2_loss: 0.3462 - g_loss: 1.8190\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.3262 - d2_loss: 0.3184 - g_loss: 1.9134\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2517 - d2_loss: 0.3096 - g_loss: 2.2995\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2754 - d2_loss: 0.2954 - g_loss: 2.3715\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2234 - d2_loss: 0.2670 - g_loss: 2.5525\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2206 - d2_loss: 0.2744 - g_loss: 2.4507\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2495 - d2_loss: 0.2791 - g_loss: 2.4636\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2460 - d2_loss: 0.3234 - g_loss: 2.5244\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2249 - d2_loss: 0.2781 - g_loss: 2.3488\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2452 - d2_loss: 0.3468 - g_loss: 2.5769\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2449 - d2_loss: 0.3280 - g_loss: 2.3379\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2151 - d2_loss: 0.2598 - g_loss: 2.7265\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2173 - d2_loss: 0.2716 - g_loss: 2.7138\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2121 - d2_loss: 0.2487 - g_loss: 2.7238\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2177 - d2_loss: 0.2671 - g_loss: 2.6354\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2128 - d2_loss: 0.2686 - g_loss: 2.6289\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2396 - d2_loss: 0.2908 - g_loss: 2.5996\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2248 - d2_loss: 0.3004 - g_loss: 2.5131\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2639 - d2_loss: 0.2834 - g_loss: 2.5670\n","18/18 [==============================] - 64s 4s/step - d1_loss: 0.2227 - d2_loss: 0.2663 - g_loss: 2.5048\n","10/18 [===============>..............] - ETA: 28s - d1_loss: 0.2404 - d2_loss: 0.2789 - g_loss: 2.3753"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-1a5abb3cf011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/OCT Gan/gan_drusen_3/Output/g_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/OCT Project/OCT Code & Dataset/OCT Gan/gan_drusen_3/Output/d_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import cv2\n","\n","im = cv2.imread('/content/drusen_1/image6660.jpeg')\n","\n","print(type(im))\n","# <class 'numpy.ndarray'>\n","\n","print(im.shape)\n","print(type(im.shape))"],"metadata":{"id":"ffvBcU2e455e"},"execution_count":null,"outputs":[]}]}